# party-model
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0.1-red)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-12.1-green)](https://developer.nvidia.com/cuda-toolkit)

A hybrid Transformer-CNN architecture for precise Phloem Area and Root Turnover Yield (party).

## ğŸ“‹ Table of Contents
- [Features](#âœ¨-features)
- [Installation](#ğŸš€-installation)
- [Data Preparation](#ğŸ“-data-preparation)
- [Training](#ğŸ¯-training)  
- [Inference](#ğŸ”-inference)
- [Configuration](#âš™ï¸-configuration)
- [Performance](#ğŸ“Š-performance)
- [Project Structure](#ğŸ“‚-project-structure)
- [License](#ğŸ“œ-license)

## âœ¨ Features
- **Dual-mode Architecture**: Combines Vision Transformer encoder with CNN decoder
- **Industrial-grade**: Supports any size of high-resolution input images
- **Real-time Processing**: 45ms inference time on NVIDIA T4 GPU
- **Adaptive Learning**: Automatic mixed precision training support

## ğŸš€ Installation
### Prerequisites
- NVIDIA GPU with CUDA 12.1+ support
- Python 3.9+


### Setup Environment
```bash
conda create -n partymodel python=3.9
conda activate partymodel
cd party-model
pip install -r requirements.txt
```
#Note: If your GPU is over RTX5060 with Blackwell, it is better to install PyTorch Nightly + CUDA 12.8

```bash
pip uninstall torch torchvision torchaudio
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```
Then remove ", verbose=True" in L85 in the file "src/train.py" and add cuda to scaler = GradScaler() in L91, then it will like scaler = GradScaler('cuda')  


## ğŸ“ Data Preparation
### Directory Structure
```
â”œâ”€â”€ data/                
â”‚   â”œâ”€â”€ pretrained model/
â”‚        â”œâ”€â”€ pretrained_model.pth
â”‚   â”œâ”€â”€ train/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ test/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ val/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
```

### Naming Convention
- Image/Mask pairs must have matching filenames:
  - `sieve_123.jpg` â†” `sieve_123.png`
- Supported resolutions: 400x400 to 2000x2000

## ğŸ¯ Training
### Start Training
```bash
python src/train.py --config configs/default.yaml
```

### Training Options
| Parameter          | Default | Description                     |
|--------------------|---------|---------------------------------|
| `--batch_size`     | 8       | GPU memory dependent           |
| `--epochs`         | 100     | Typical range: 100-300          |
| `--lr`             | 1e-4    | AdamW initial learning rate    |
| `--image_size`     | 224     | ViT input dimension            |

### Training Monitoring
TensorBoard integration:
```bash
tensorboard --logdir outputs/tensorboard
```

## ğŸ” Inference
### Single Image Prediction
```bash
python src/predict.py \
    --model_path outputs/models/sievenet_epoch100.pth \
    --input data/test/images/demo.jpg \
    --output outputs/predictions/result.png
```

### Batch Prediction
```bash
python src/predict_batch.py \
    --model_path outputs/models/sievenet_epoch100.pth \
    --input_dir data/test/images/ \
    --output_dir outputs/predictions/
```

## âš™ï¸ Configuration
Edit `configs/default.yaml`:
```yaml
data_path: "data/"
batch_size: 4
epochs: 250
lr: 1.0e-5         # ä½¿ç”¨ç§‘å­¸è¨ˆæ•¸æ³•è¡¨ç¤º
patch_size: 400    # å¯èª¿æ•´ï¼Œå€¼è¶Šå°è­˜åˆ¥è¶Šç²¾ç´°
val_split: 0.2     # å°æ•¸å½¢å¼

# æ¨¡å‹æ¶æ§‹é¸é …ï¼š
#  - "TransUNet": ä½¿ç”¨åŸå§‹ TransUNet æ¨¡å‹
#  - "TransUNetWithTimm": ä½¿ç”¨ timm è¼‰å…¥çš„ ViT encoderï¼Œä¸¦ä¿æŒåŸæœ‰ decoder çµæ§‹
model_type: "TransUNet"

num_decoder_conv_layers: 80   # å¯éš¨æ„ä¿®æ”¹ decoder ä¸­å·ç©å±¤æ•¸é‡ï¼ˆä¾‹å¦‚é è¨­ 30 å±¤ï¼‰ï¼Œæ ¹æ“šéå¾€çš„ç ”ç©¶ï¼Œå±¤æ•¸å¤ªé«˜æœƒä¸Ÿå¤±ç´°ç¯€ï¼Œå¤ªä½æœƒåˆ†è¾¨ä¸ä½³ï¼Œå¤§æ¦‚20-30å±¤ä¹‹é–“
#25å±¤å¥½åƒä¹Ÿä¸å¤ªå¯ä»¥ï¼Œç›®å‰æ¸¬è©¦80-120å°ç¯©ç®¡çš„è¾¨è­˜é‚„ä¸éŒ¯

```

## ğŸ“Š Performance
### Evaluation Metrics (Test Set)
| Metric        | Value  |
|---------------|--------|
| Dice Score    | 0.92   |
| IoU           | 0.87   |
| Precision     | 0.94   |
| Recall        | 0.91   |

### Hardware Benchmark
| GPU           | Inference Time | Memory Usage |
|---------------|----------------|--------------|
| NVIDIA T4     | 45ms           | 3.2GB        |
| RTX 3090      | 28ms           | 4.1GB        |
| A100 (40GB)   | 18ms           | 5.8GB        |

## ğŸ“‚ Project Structure
```
party model/
â”œâ”€â”€ configs/              # Configuration templates
â”‚   â”œâ”€â”€ default.yaml
â”œâ”€â”€ data/                # Dataset storage
â”‚   â”œâ”€â”€ pretrained model/
â”‚        â”œâ”€â”€ pretrained_model.pth
â”‚   â”œâ”€â”€ train/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ test/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ val/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”œâ”€â”€ outputs/             # Training artifacts
â”‚   â”œâ”€â”€ models/          # Checkpoints
â”‚   â”œâ”€â”€ predictions/     # Inference results
â”‚   â””â”€â”€ tensorboard/     # Training metrics
â”œâ”€â”€ src/                 # Core implementation
â”‚   â”œâ”€â”€ dataset.py        # æ•¸æ“šè®€å–èˆ‡å¢å¼·
â”‚   â”œâ”€â”€ model.py          # åŸå§‹ TransUNet æ¨¡å‹
â”‚   â”œâ”€â”€ model_with_timm.py# åŸºæ–¼ timm çš„ ViT encoder æ¨¡å‹
â”‚   â”œâ”€â”€ losses.py         # æå¤±å‡½æ•¸å¯¦ç¾
â”‚   â”œâ”€â”€ train.py          # æ¨¡å‹è¨“ç·´æµç¨‹
â”‚   â”œâ”€â”€ predict.py        # é æ¸¬èˆ‡æ¨ç†æ¨¡å¡Š
â”‚   â”œâ”€â”€ utils.py          # è¼”åŠ©å·¥å…·ï¼ˆä¾‹å¦‚å¯è¦–åŒ–ï¼‰
â”‚   â””â”€â”€ postprocess.py    # åˆ†å‰²çµæœå¾Œè™•ç†æ¨¡å¡Š
â””â”€â”€ requirements.txt     # Dependency list
â””â”€â”€ README,md
```

## ğŸ“œ License
Apache 2.0 License. See [LICENSE](LICENSE) for details.
