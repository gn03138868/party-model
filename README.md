# party-model

A hybrid Transformer-CNN architecture for precise sieve mesh segmentation in industrial inspection scenarios.

## ğŸ“‹ Table of Contents
- [Features](#âœ¨-features)
- [Installation](#ğŸš€-installation)
- [Data Preparation](#ğŸ“-data-preparation)
- [Training](#ğŸ¯-training)  
- [Inference](#ğŸ”-inference)
- [Configuration](#âš™ï¸-configuration)
- [Performance](#ğŸ“Š-performance)
- [Project Structure](#ğŸ“‚-project-structure)
- [License](#ğŸ“œ-license)

## âœ¨ Features
- **Dual-mode Architecture**: Combines Vision Transformer encoder with CNN decoder
- **Industrial-grade**: Supports 400x400 high-resolution input with 16-bit precision
- **Real-time Processing**: 45ms inference time on NVIDIA T4 GPU
- **Adaptive Learning**: Automatic mixed precision training support

## ğŸš€ Installation
### Prerequisites
- NVIDIA GPU with CUDA 12.2+ support
- Python 3.9+

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0.1-red)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-12.2-green)](https://developer.nvidia.com/cuda-toolkit)


### Setup Environment
```bash
conda create -n sievenet python=3.9
conda activate sievenet
pip install -r requirements.txt
```

## ğŸ“ Data Preparation
### Directory Structure
```
â”œâ”€â”€ data/                
â”‚   â”œâ”€â”€ pretrained model/
â”‚        â”œâ”€â”€ pretrained_model.pth
â”‚   â”œâ”€â”€ train/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ test/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ val/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
```

### Naming Convention
- Image/Mask pairs must have matching filenames:
  - `sieve_123.jpg` â†” `sieve_123.png`
- Supported resolutions: 400x400 to 2000x2000

## ğŸ¯ Training
### Start Training
```bash
python src/train.py --config configs/default.yaml
```

### Training Options
| Parameter          | Default | Description                     |
|--------------------|---------|---------------------------------|
| `--batch_size`     | 8       | GPU memory dependent           |
| `--epochs`         | 100     | Typical range: 100-300          |
| `--lr`             | 1e-4    | AdamW initial learning rate    |
| `--image_size`     | 224     | ViT input dimension            |

### Training Monitoring
TensorBoard integration:
```bash
tensorboard --logdir outputs/tensorboard
```

## ğŸ” Inference
### Single Image Prediction
```bash
python src/predict.py \
    --model_path outputs/models/sievenet_epoch100.pth \
    --input data/test/images/demo.jpg \
    --output outputs/predictions/result.png
```

### Batch Prediction
```bash
python src/predict_batch.py \
    --model_path outputs/models/sievenet_epoch100.pth \
    --input_dir data/test/images/ \
    --output_dir outputs/predictions/
```

## âš™ï¸ Configuration
Edit `configs/default.yaml`:
```yaml
data_path: "data/"
batch_size: 8
epochs: 100
lr: 0.0001
image_size: 224
mixed_precision: True  # Enable AMP training
```

## ğŸ“Š Performance
### Evaluation Metrics (Test Set)
| Metric        | Value  |
|---------------|--------|
| Dice Score    | 0.92   |
| IoU           | 0.87   |
| Precision     | 0.94   |
| Recall        | 0.91   |

### Hardware Benchmark
| GPU           | Inference Time | Memory Usage |
|---------------|----------------|--------------|
| NVIDIA T4     | 45ms           | 3.2GB        |
| RTX 3090      | 28ms           | 4.1GB        |
| A100 (40GB)   | 18ms           | 5.8GB        |

## ğŸ“‚ Project Structure
```
party-model/
â”œâ”€â”€ configs/              # Configuration templates
â”‚   â”œâ”€â”€ default.yaml
â”œâ”€â”€ data/                # Dataset storage
â”‚   â”œâ”€â”€ pretrained model/
â”‚        â”œâ”€â”€ pretrained_model.pth
â”‚   â”œâ”€â”€ train/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ test/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ val/
â”‚        â”œâ”€â”€ images/
â”‚        â”œâ”€â”€ masks/
â”œâ”€â”€ outputs/             # Training artifacts
â”‚   â”œâ”€â”€ models/          # Checkpoints
â”‚   â”œâ”€â”€ predictions/     # Inference results
â”‚   â””â”€â”€ tensorboard/     # Training metrics
â”œâ”€â”€ src/                 # Core implementation
â”‚   â”œâ”€â”€ dataset.py        # æ•¸æ“šè®€å–èˆ‡å¢å¼·
â”‚   â”œâ”€â”€ model.py          # åŸå§‹ TransUNet æ¨¡å‹
â”‚   â”œâ”€â”€ model_with_timm.py# åŸºæ–¼ timm çš„ ViT encoder æ¨¡å‹
â”‚   â”œâ”€â”€ losses.py         # æå¤±å‡½æ•¸å¯¦ç¾
â”‚   â”œâ”€â”€ train.py          # æ¨¡å‹è¨“ç·´æµç¨‹
â”‚   â”œâ”€â”€ predict.py        # é æ¸¬èˆ‡æ¨ç†æ¨¡å¡Š
â”‚   â”œâ”€â”€ utils.py          # è¼”åŠ©å·¥å…·ï¼ˆä¾‹å¦‚å¯è¦–åŒ–ï¼‰
â”‚   â””â”€â”€ postprocess.py    # åˆ†å‰²çµæœå¾Œè™•ç†æ¨¡å¡Š
â””â”€â”€ requirements.txt     # Dependency list
â””â”€â”€ README,md
```

## ğŸ“œ License
Apache 2.0 License. See [LICENSE](LICENSE) for details.
